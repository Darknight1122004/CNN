{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zPj8pVFlYwqS"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "Z1_uM-SX0o77",
    "outputId": "aa638ab3-e7a5-41d4-96be-45833348479d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.17.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2E_Zthm402Q3"
   },
   "source": [
    "Part 1:data preprocessing(training set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "oF1ez4AZ0zvK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen= ImageDataGenerator(\n",
    "   rescale=1./255,\n",
    "   shear_range=0.2,\n",
    "   zoom_range=0.2,\n",
    "   horizontal_flip=True)\n",
    "training_set=train_datagen.flow_from_directory(\n",
    "    r'C:\\Users\\ARYANSH R\\Downloads\\dataset\\dataset\\training_set',\n",
    "    target_size=(64,64),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bk7Pu_eFFXdS"
   },
   "source": [
    "data preprocessing(test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "oUr2sIYK1-ir"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen= ImageDataGenerator(\n",
    "   rescale=1./255,\n",
    "   shear_range=0.2,\n",
    "   zoom_range=0.2,\n",
    "   horizontal_flip=True)\n",
    "test_set=train_datagen.flow_from_directory(\n",
    "    r'C:\\Users\\ARYANSH R\\Downloads\\dataset\\dataset\\test_set',\n",
    "    target_size=(64,64),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrcVfUS5GcF9"
   },
   "source": [
    "part2:Building the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "_spW0bZ8GgOF"
   },
   "outputs": [],
   "source": [
    "cnn=tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bmr9JABEJQbj"
   },
   "source": [
    "Convolution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "l0MraPK3G3qS"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XRKnNOiNJXt9"
   },
   "source": [
    "Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "ZI5pyrmiJIM-"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDnGOR4ZLBOL"
   },
   "source": [
    "adding a second convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "sWHTPg5uLAHc"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu',input_shape=[64,64,3]))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imlk6QonL4Uq"
   },
   "source": [
    "Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "UvPoSGRnMRKT"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMtyf1PDM6yP"
   },
   "source": [
    "Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "VKktSJ6SNPhy"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128,activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gke1APA8N3RT"
   },
   "source": [
    "Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "MH9ur0WLN7JY"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IDfg3NaJSzmZ"
   },
   "source": [
    "compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "CbVGk7VtS1hM"
   },
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "XWnsXDahTFs-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ARYANSH R\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 267ms/step - accuracy: 0.5114 - loss: 0.6941 - val_accuracy: 0.5650 - val_loss: 0.6809\n",
      "Epoch 2/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 253ms/step - accuracy: 0.5892 - loss: 0.6684 - val_accuracy: 0.6565 - val_loss: 0.6293\n",
      "Epoch 3/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 240ms/step - accuracy: 0.6399 - loss: 0.6322 - val_accuracy: 0.6460 - val_loss: 0.6260\n",
      "Epoch 4/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 257ms/step - accuracy: 0.6881 - loss: 0.5965 - val_accuracy: 0.7060 - val_loss: 0.5743\n",
      "Epoch 5/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 251ms/step - accuracy: 0.7077 - loss: 0.5635 - val_accuracy: 0.7285 - val_loss: 0.5445\n",
      "Epoch 6/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 234ms/step - accuracy: 0.7225 - loss: 0.5363 - val_accuracy: 0.7380 - val_loss: 0.5260\n",
      "Epoch 7/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 232ms/step - accuracy: 0.7524 - loss: 0.5024 - val_accuracy: 0.7690 - val_loss: 0.4869\n",
      "Epoch 8/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 234ms/step - accuracy: 0.7616 - loss: 0.4997 - val_accuracy: 0.7580 - val_loss: 0.5011\n",
      "Epoch 9/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 237ms/step - accuracy: 0.7839 - loss: 0.4615 - val_accuracy: 0.7850 - val_loss: 0.4746\n",
      "Epoch 10/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 234ms/step - accuracy: 0.7815 - loss: 0.4547 - val_accuracy: 0.7845 - val_loss: 0.4609\n",
      "Epoch 11/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 233ms/step - accuracy: 0.7907 - loss: 0.4401 - val_accuracy: 0.7955 - val_loss: 0.4597\n",
      "Epoch 12/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 235ms/step - accuracy: 0.7946 - loss: 0.4311 - val_accuracy: 0.7845 - val_loss: 0.4618\n",
      "Epoch 13/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 237ms/step - accuracy: 0.8091 - loss: 0.4158 - val_accuracy: 0.7825 - val_loss: 0.4603\n",
      "Epoch 14/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 232ms/step - accuracy: 0.8119 - loss: 0.4078 - val_accuracy: 0.7645 - val_loss: 0.5068\n",
      "Epoch 15/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 236ms/step - accuracy: 0.8263 - loss: 0.3866 - val_accuracy: 0.7960 - val_loss: 0.4395\n",
      "Epoch 16/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 230ms/step - accuracy: 0.8280 - loss: 0.3871 - val_accuracy: 0.8095 - val_loss: 0.4387\n",
      "Epoch 17/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 234ms/step - accuracy: 0.8210 - loss: 0.3876 - val_accuracy: 0.8200 - val_loss: 0.4145\n",
      "Epoch 18/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 231ms/step - accuracy: 0.8302 - loss: 0.3705 - val_accuracy: 0.8120 - val_loss: 0.4243\n",
      "Epoch 19/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 232ms/step - accuracy: 0.8417 - loss: 0.3564 - val_accuracy: 0.8070 - val_loss: 0.3988\n",
      "Epoch 20/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 235ms/step - accuracy: 0.8497 - loss: 0.3396 - val_accuracy: 0.8060 - val_loss: 0.4300\n",
      "Epoch 21/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 236ms/step - accuracy: 0.8538 - loss: 0.3292 - val_accuracy: 0.8250 - val_loss: 0.4142\n",
      "Epoch 22/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 234ms/step - accuracy: 0.8509 - loss: 0.3303 - val_accuracy: 0.8305 - val_loss: 0.4090\n",
      "Epoch 23/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 236ms/step - accuracy: 0.8558 - loss: 0.3237 - val_accuracy: 0.8190 - val_loss: 0.4225\n",
      "Epoch 24/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 232ms/step - accuracy: 0.8671 - loss: 0.3058 - val_accuracy: 0.8185 - val_loss: 0.4201\n",
      "Epoch 25/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 236ms/step - accuracy: 0.8679 - loss: 0.3000 - val_accuracy: 0.8205 - val_loss: 0.4338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x29201bcd0a0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x=training_set,validation_data=test_set,epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRxJcc1DV-vJ"
   },
   "source": [
    "single test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "9ZTPSGgAVp4-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image=image.load_img(r'C:\\Users\\ARYANSH R\\Downloads\\dataset\\dataset\\single_prediction\\cat_or_dog_1.jpg', target_size = (64, 64))\n",
    "test_image=image.img_to_array(test_image)\n",
    "test_image=np.expand_dims(test_image,axis=0)\n",
    "result=cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0]==1:\n",
    "  prediction='dog'\n",
    "else:\n",
    "    prediction='cat'\n",
    "    print(prediction)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
